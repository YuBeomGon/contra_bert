{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vig20H9St5es"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hj9zPQ_YuR3r"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U7rbc13hwDAM"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\", do_lower_case=False)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-multilingual-cased\", num_labels=20)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2qIUI6OGukuv"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('./gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlN9aoqpu2vW"
   },
   "outputs": [],
   "source": [
    "cd /content/gdrive/My\\ Drive/DeepLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cub2JrTWu6Se"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./petcharts/train.csv')\n",
    "test_df = pd.read_csv('./petcharts/test.csv')\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q7gqs4q-vgAr"
   },
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "  def __init__(self, df):\n",
    "    self.df = df\n",
    "    self.pattern = r'[0-9]|[a-zA-Z]|[$-_@.&+!*?;:~\\(\\)\\[\\]<>/\\'\"\\\\]+'\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    text = self.df.iloc[idx, 8]\n",
    "    label = self.df.iloc[idx, 10]\n",
    "    return re.sub(self.pattern, '', text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbUZuQvfBu7y"
   },
   "outputs": [],
   "source": [
    "train_dataset = PetDataset(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nOWuCZzVwXdR"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "itr = 1\n",
    "p_itr = 512\n",
    "epochs = 64\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  for text, label in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "    padded_list = [e[:512] + [0] * (512-len(e[:512])) for e in encoded_list]\n",
    "    sample = torch.tensor(padded_list)\n",
    "    sample, label = sample.to(device), label.to(device)\n",
    "    labels = torch.tensor(label)\n",
    "    outputs = model(sample, labels=labels)\n",
    "    loss, logits = outputs\n",
    "\n",
    "    pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "    correct = pred.eq(labels)\n",
    "    total_correct += correct.sum().item()\n",
    "    total_len += len(labels)\n",
    "    total_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if itr % p_itr == 0:\n",
    "      print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
    "      total_loss = 0\n",
    "      total_len = 0\n",
    "      total_correct = 0\n",
    "\n",
    "    itr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BRy5RHZ_605e"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_dataset = PetDataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=2)\n",
    "\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "for text, label in test_loader:\n",
    "  encoded_list = [tokenizer.encode(t, add_special_token=True) for t in text]\n",
    "  padded_list = [e[:512] + [0] * (512-len(e[:512])) for e in encoded_list]\n",
    "  sample = torch.tensor(padded_list)\n",
    "  sample, label = sample.to(device), label.to(device)\n",
    "  labels = torch.tensor(label)\n",
    "  outputs = model(sample, labels=labels)\n",
    "  _, logits = outputs\n",
    "  \n",
    "  pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "  print(labels, pred)\n",
    "  correct = pred.eq(labels)\n",
    "  total_correct += correct.sum().item()\n",
    "  total_len += len(labels)\n",
    "\n",
    "print('Test accuracy: ', total_correct / total_len)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMPQ3XY5FDYCCF7G7hBHscW",
   "collapsed_sections": [],
   "name": "bert.petcharts.classification.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
